{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f912cfd",
   "metadata": {},
   "source": [
    "# Pyspark on kubernetes\n",
    "   * https://alphatango086.medium.com/pyspark-on-kubernetes-71dcbd034c60\n",
    "   * https://spark.apache.org/docs/3.2.0/running-on-kubernetes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec69fb",
   "metadata": {},
   "source": [
    "# Client Mode Networking\n",
    "   * https://spark.apache.org/docs/3.2.0/running-on-kubernetes.html#client-mode-networking\n",
    "   \n",
    "Spark executors must be able to connect to the Spark driver over a hostname and a port that is routable from the Spark executors. The specific network configuration that will be required for Spark to work in client mode will vary per setup. If you run your driver inside a Kubernetes pod, **you can use a headless service to allow your driver pod to be routable from the executors by a stable hostname.** \n",
    "\n",
    "When deploying your headless service, ensure that the service’s label selector will only match the driver pod and no other pods; it is recommended to assign your driver pod a sufficiently unique label and to use that label in the label selector of the headless service.\n",
    "\n",
    "Specify the driver’s hostname via spark.driver.host and your spark driver’s port to spark.driver.port."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2312a11",
   "metadata": {},
   "source": [
    "   * https://jaceklaskowski.github.io/spark-kubernetes-book/demo/running-pyspark-application-on-minikube/#create-kubernetes-resources\n",
    "   * https://www.kdnuggets.com/2020/08/containerization-pyspark-kubernetes.html\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27507855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "# Create Spark config for our Kubernetes based cluster manager\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"k8s://https://kubernetes.default.svc\")\n",
    "sparkConf.setAppName(\"spark\")\n",
    "\n",
    "sparkConf.set(\"spark.kubernetes.container.image\", \"registry.minikube/spark-base-python-3.2:master\")\n",
    "\n",
    "sparkConf.set(\"spark.kubernetes.namespace\", \"zeppelin\")\n",
    "\n",
    "sparkConf.set(\"spark.executor.instances\", \"3\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"512m\")\n",
    "sparkConf.set(\"spark.executor.memory\", \"512m\")\n",
    "\n",
    "sparkConf.set(\"spark.kubernetes.pyspark.pythonVersion\", \"3\")\n",
    "\n",
    "sparkConf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"zeppelin-server\")\n",
    "sparkConf.set(\"spark.kubernetes.authenticate.serviceAccountName\", \"zeppelin-server\")\n",
    "\n",
    "sparkConf.set(\"spark.driver.host\", \"jupyter-driver.zeppelin.svc.cluster2.xpt\")\n",
    "sparkConf.set(\"spark.driver.port\", \"29413\")\n",
    "\n",
    "sparkConf.set(\"fs.s3a.endpoint\", \"https://minio.minio-tenant-1.svc.cluster2.xpt\")\n",
    "sparkConf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sparkConf.set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "sparkConf.set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sparkConf.set(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\")\n",
    "sparkConf.set(\"spark.sql.warehouse.dir\", \"s3a://spark/warehouse\")\n",
    "sparkConf.set(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "sparkConf.set(\"spark.hadoop.hive.metastore.uris\", \"thrift://hive-metastore.hive.svc.cluster2.xpt:9083\")\n",
    "\n",
    "# Initialize our Spark cluster, this will actually\n",
    "# generate the worker nodes.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1ac7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-driver.zeppelin.svc.cluster2.xpt:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>k8s://https://kubernetes.default.svc</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=k8s://https://kubernetes.default.svc appName=spark>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e205ff2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default configurations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.executor.instances', '3'),\n",
       " ('spark.hadoop.hive.metastore.uris',\n",
       "  'thrift://hive-metastore.hive.svc.cluster2.xpt:9083'),\n",
       " ('spark.sql.warehouse.dir', 's3a://spark/warehouse'),\n",
       " ('spark.master', 'k8s://https://kubernetes.default.svc'),\n",
       " ('spark.kubernetes.container.image',\n",
       "  'registry.minikube/spark-base-python-3.2:master'),\n",
       " ('spark.kubernetes.authenticate.serviceAccountName', 'zeppelin-server'),\n",
       " ('spark.kubernetes.pyspark.pythonVersion', '3'),\n",
       " ('spark.kubernetes.executor.podNamePrefix', 'spark-f565ed8cde6de8df'),\n",
       " ('spark.app.name', 'spark'),\n",
       " ('spark.jars.packages',\n",
       "  'org.apache.spark:spark-avro_2.12:3.2.4,io.delta:delta-core_2.12:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.3.0,org.apache.hadoop:hadoop-aws:3.2.4,org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.4,io.acryl:datahub-spark-lineage:0.8.23,com.amazon.deequ:deequ:2.0.1-spark-3.2'),\n",
       " ('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem'),\n",
       " ('spark.files',\n",
       "  'file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.2.4.jar,file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.0.2.jar,file:///root/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.2_2.12-1.3.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.2.4.jar,file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.4.jar,file:///root/.ivy2/jars/io.acryl_datahub-spark-lineage-0.8.23.jar,file:///root/.ivy2/jars/com.amazon.deequ_deequ-2.0.1-spark-3.2.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.8.jar,file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///root/.ivy2/jars/io.delta_delta-storage-2.0.2.jar,file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar,file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.4.jar,file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.1.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,file:///root/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,file:///root/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.10.jar,file:///root/.ivy2/jars/org.scalanlp_breeze_2.12-0.13.2.jar,file:///root/.ivy2/jars/org.scalanlp_breeze-macros_2.12-0.13.2.jar,file:///root/.ivy2/jars/com.github.fommil.netlib_core-1.1.2.jar,file:///root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1-javadoc.jar,file:///root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar,file:///root/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar,file:///root/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar,file:///root/.ivy2/jars/org.apache.commons_commons-math3-3.2.jar,file:///root/.ivy2/jars/org.spire-math_spire_2.12-0.13.0.jar,file:///root/.ivy2/jars/com.chuusai_shapeless_2.12-2.3.2.jar,file:///root/.ivy2/jars/junit_junit-4.8.2.jar,file:///root/.ivy2/jars/org.spire-math_spire-macros_2.12-0.13.0.jar,file:///root/.ivy2/jars/org.typelevel_machinist_2.12-0.6.1.jar,file:///root/.ivy2/jars/org.typelevel_macro-compat_2.12-1.1.1.jar'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('fs.s3a.aws.credentials.provider',\n",
       "  'com.amazonaws.auth.DefaultAWSCredentialsProviderChain'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.2.4.jar,/root/.ivy2/jars/io.delta_delta-core_2.12-2.0.2.jar,/root/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.2_2.12-1.3.0.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.2.4.jar,/root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.4.jar,/root/.ivy2/jars/io.acryl_datahub-spark-lineage-0.8.23.jar,/root/.ivy2/jars/com.amazon.deequ_deequ-2.0.1-spark-3.2.jar,/root/.ivy2/jars/org.tukaani_xz-1.8.jar,/root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,/root/.ivy2/jars/io.delta_delta-storage-2.0.2.jar,/root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,/root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,/root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar,/root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.4.jar,/root/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.1.jar,/root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,/root/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,/root/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,/root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,/root/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,/root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,/root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.10.jar,/root/.ivy2/jars/org.scalanlp_breeze_2.12-0.13.2.jar,/root/.ivy2/jars/org.scalanlp_breeze-macros_2.12-0.13.2.jar,/root/.ivy2/jars/com.github.fommil.netlib_core-1.1.2.jar,/root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1-javadoc.jar,/root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar,/root/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar,/root/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar,/root/.ivy2/jars/org.apache.commons_commons-math3-3.2.jar,/root/.ivy2/jars/org.spire-math_spire_2.12-0.13.0.jar,/root/.ivy2/jars/com.chuusai_shapeless_2.12-2.3.2.jar,/root/.ivy2/jars/junit_junit-4.8.2.jar,/root/.ivy2/jars/org.spire-math_spire-macros_2.12-0.13.0.jar,/root/.ivy2/jars/org.typelevel_machinist_2.12-0.6.1.jar,/root/.ivy2/jars/org.typelevel_macro-compat_2.12-1.1.1.jar'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/com.chuusai_shapeless_2.12-2.3.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/com.amazon.deequ_deequ-2.0.1-spark-3.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.commons_commons-math3-3.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/commons-logging_commons-logging-1.1.3.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/junit_junit-4.8.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.spark-project.spark_unused-1.0.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.scalanlp_breeze_2.12-0.13.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.hadoop_hadoop-aws-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.iceberg_iceberg-spark-runtime-3.2_2.12-1.3.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.lz4_lz4-java-1.7.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/com.google.code.findbugs_jsr305-3.0.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.scala-lang_scala-reflect-2.12.10.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.typelevel_machinist_2.12-0.6.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.typelevel_macro-compat_2.12-1.1.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.slf4j_slf4j-api-1.7.30.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/net.sourceforge.f2j_arpack_combined_all-0.1-javadoc.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.antlr_antlr4-runtime-4.8.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.scalanlp_breeze-macros_2.12-0.13.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.tukaani_xz-1.8.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.commons_commons-pool2-2.6.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/io.delta_delta-storage-2.0.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.spire-math_spire_2.12-0.13.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.spark_spark-avro_2.12-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/io.acryl_datahub-spark-lineage-0.8.23.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/com.github.fommil.netlib_core-1.1.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/com.github.rwl_jtransforms-2.4.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.spire-math_spire-macros_2.12-0.13.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.kafka_kafka-clients-2.8.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/io.delta_delta-core_2.12-2.0.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/jars/net.sf.opencsv_opencsv-2.3.jar'),\n",
       " ('spark.driver.port', '29413'),\n",
       " ('spark.app.initial.file.urls',\n",
       "  'spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/com.amazon.deequ_deequ-2.0.1-spark-3.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.hadoop_hadoop-client-api-3.3.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.lz4_lz4-java-1.7.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.scalanlp_breeze_2.12-0.13.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.iceberg_iceberg-spark-runtime-3.2_2.12-1.3.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/io.acryl_datahub-spark-lineage-0.8.23.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/com.chuusai_shapeless_2.12-2.3.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/com.google.code.findbugs_jsr305-3.0.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.spire-math_spire-macros_2.12-0.13.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.kafka_kafka-clients-2.8.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.typelevel_macro-compat_2.12-1.1.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.slf4j_slf4j-api-1.7.30.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.spire-math_spire_2.12-0.13.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.xerial.snappy_snappy-java-1.1.8.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.scalanlp_breeze-macros_2.12-0.13.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/com.github.rwl_jtransforms-2.4.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.commons_commons-pool2-2.6.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/junit_junit-4.8.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/commons-logging_commons-logging-1.1.3.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.spark_spark-avro_2.12-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/net.sourceforge.f2j_arpack_combined_all-0.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.tukaani_xz-1.8.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.scala-lang_scala-reflect-2.12.10.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.typelevel_machinist_2.12-0.6.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.spark-project.spark_unused-1.0.0.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/io.delta_delta-storage-2.0.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/io.delta_delta-core_2.12-2.0.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.antlr_antlr4-runtime-4.8.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.hadoop_hadoop-aws-3.2.4.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.commons_commons-math3-3.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/net.sf.opencsv_opencsv-2.3.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/com.github.fommil.netlib_core-1.1.2.jar,spark://jupyter-driver.zeppelin.svc.cluster2.xpt:29413/files/net.sourceforge.f2j_arpack_combined_all-0.1-javadoc.jar'),\n",
       " ('fs.s3a.path.style.access', 'true'),\n",
       " ('spark.executor.memory', '512m'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.kubernetes.authenticate.driver.serviceAccountName',\n",
       "  'zeppelin-server'),\n",
       " ('fs.s3a.endpoint', 'https://minio.minio-tenant-1.svc.cluster2.xpt'),\n",
       " ('spark.driver.memory', '512m'),\n",
       " ('spark.app.id', 'spark-application-1704538794323'),\n",
       " ('spark.kubernetes.namespace', 'zeppelin'),\n",
       " ('spark.driver.host', 'jupyter-driver.zeppelin.svc.cluster2.xpt'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('fs.s3a.connection.ssl.enabled', 'true'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.jars',\n",
       "  'file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.2.4.jar,file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.0.2.jar,file:///root/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.2_2.12-1.3.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.2.4.jar,file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.4.jar,file:///root/.ivy2/jars/io.acryl_datahub-spark-lineage-0.8.23.jar,file:///root/.ivy2/jars/com.amazon.deequ_deequ-2.0.1-spark-3.2.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.8.jar,file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///root/.ivy2/jars/io.delta_delta-storage-2.0.2.jar,file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar,file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.4.jar,file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.1.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,file:///root/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,file:///root/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.10.jar,file:///root/.ivy2/jars/org.scalanlp_breeze_2.12-0.13.2.jar,file:///root/.ivy2/jars/org.scalanlp_breeze-macros_2.12-0.13.2.jar,file:///root/.ivy2/jars/com.github.fommil.netlib_core-1.1.2.jar,file:///root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1-javadoc.jar,file:///root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar,file:///root/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar,file:///root/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar,file:///root/.ivy2/jars/org.apache.commons_commons-math3-3.2.jar,file:///root/.ivy2/jars/org.spire-math_spire_2.12-0.13.0.jar,file:///root/.ivy2/jars/com.chuusai_shapeless_2.12-2.3.2.jar,file:///root/.ivy2/jars/junit_junit-4.8.2.jar,file:///root/.ivy2/jars/org.spire-math_spire-macros_2.12-0.13.0.jar,file:///root/.ivy2/jars/org.typelevel_machinist_2.12-0.6.1.jar,file:///root/.ivy2/jars/org.typelevel_macro-compat_2.12-1.1.1.jar'),\n",
       " ('spark.app.startTime', '1704538792865'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///root/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.2.4.jar,file:///root/.ivy2/jars/io.delta_delta-core_2.12-2.0.2.jar,file:///root/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.2_2.12-1.3.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.2.4.jar,file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.2.4.jar,file:///root/.ivy2/jars/io.acryl_datahub-spark-lineage-0.8.23.jar,file:///root/.ivy2/jars/com.amazon.deequ_deequ-2.0.1-spark-3.2.jar,file:///root/.ivy2/jars/org.tukaani_xz-1.8.jar,file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///root/.ivy2/jars/io.delta_delta-storage-2.0.2.jar,file:///root/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.901.jar,file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.2.4.jar,file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-2.8.1.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.1.jar,file:///root/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar,file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.1.jar,file:///root/.ivy2/jars/org.apache.htrace_htrace-core4-4.1.0-incubating.jar,file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.10.jar,file:///root/.ivy2/jars/org.scalanlp_breeze_2.12-0.13.2.jar,file:///root/.ivy2/jars/org.scalanlp_breeze-macros_2.12-0.13.2.jar,file:///root/.ivy2/jars/com.github.fommil.netlib_core-1.1.2.jar,file:///root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1-javadoc.jar,file:///root/.ivy2/jars/net.sourceforge.f2j_arpack_combined_all-0.1.jar,file:///root/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar,file:///root/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar,file:///root/.ivy2/jars/org.apache.commons_commons-math3-3.2.jar,file:///root/.ivy2/jars/org.spire-math_spire_2.12-0.13.0.jar,file:///root/.ivy2/jars/com.chuusai_shapeless_2.12-2.3.2.jar,file:///root/.ivy2/jars/junit_junit-4.8.2.jar,file:///root/.ivy2/jars/org.spire-math_spire-macros_2.12-0.13.0.jar,file:///root/.ivy2/jars/org.typelevel_machinist_2.12-0.6.1.jar,file:///root/.ivy2/jars/org.typelevel_macro-compat_2.12-1.1.1.jar'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Default configurations\")\n",
    "spark.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc5260e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv_us_cities=spark.read.csv(\"s3a://bronze/kaggle/us_cities_by_pop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c83ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_us_cities.createOrReplaceTempView(\"csv_us_cities\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e795e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+-----------+-----------+--------------+------------+------------+--------------+--------------+-------------+------------+\n",
      "| _c0|         _c1|         _c2|        _c3|        _c4|           _c5|         _c6|         _c7|           _c8|           _c9|         _c10|        _c11|\n",
      "+----+------------+------------+-----------+-----------+--------------+------------+------------+--------------+--------------+-------------+------------+\n",
      "|rank|        city|       state|2020_census|2010_census|percent_change|land_area_mi|land_area_km|pop_density_mi|pop_density_km|degrees_north|degrees_west|\n",
      "|   1|    New York|    New York|    8804190|    8175133|          7.69|       300.5|       778.3|         29298|         11312|        40.66|       73.93|\n",
      "|   2| Los Angeles|  California|    3898747|    3792621|           2.8|       469.5|        1216|          8304|          3206|        34.01|      118.41|\n",
      "|   3|     Chicago|    Illinois|    2746388|    2695598|          1.88|       227.7|       589.7|         12061|          4657|        41.83|       87.68|\n",
      "|   4|     Houston|       Texas|    2304580|    2099451|          9.77|       640.4|      1658.6|          3599|          1390|        29.78|       95.39|\n",
      "|   5|     Phoenix|     Arizona|    1608139|    1445632|         11.24|         518|      1341.6|          3105|          1199|        33.57|      112.09|\n",
      "|   6|Philadelphia|Pennsylvania|    1603797|    1526006|           5.1|       134.4|       348.1|         11933|          4607|           40|       75.13|\n",
      "|   7| San Antonio|       Texas|    1434625|    1327407|          8.08|       498.8|      1291.9|          2876|          1110|        29.47|       98.52|\n",
      "|   8|   San Diego|  California|    1386932|    1307402|          6.08|       325.9|       844.1|          4256|          1643|        32.81|      117.13|\n",
      "|   9|      Dallas|       Texas|    1304379|    1197816|           8.9|       339.6|       879.6|          3841|          1483|        32.79|       96.76|\n",
      "+----+------------+------------+-----------+-----------+--------------+------------+------------+--------------+--------------+-------------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv_us_cities.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
